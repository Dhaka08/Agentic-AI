{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6e4b0f7c"
   },
   "source": [
    "# Fine-Tuning a Small Language Model on SQuAD Dataset\n",
    "\n",
    "## Task Overview\n",
    "This notebook demonstrates fine-tuning a small language model (DistilBERT with ~66M parameters) on the SQuAD dataset for Question Answering task.\n",
    "\n",
    "### Steps:\n",
    "1. Install required libraries\n",
    "2. Load and explore the dataset\n",
    "3. Preprocess data (tokenization)\n",
    "4. Load a pre-trained SLM\n",
    "5. Fine-tune the model\n",
    "6. Evaluate using EM and F1 metrics\n",
    "\n",
    "## Step 1: Install Required Libraries\n",
    "\n",
    "pip install transformers datasets accelerate evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6334b2ad"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542,
     "referenced_widgets": [
      "7c47de5f6c5b448087a94bc64d14d23f",
      "d826a23b8ca74d938d9d46f2222dc3da",
      "a8e5a621b7ea4e568dbaa3800a9b7b26",
      "585502fa817843bd992701b019f912dc",
      "1f73550383c64dd0a3a326cb11e5139c",
      "0087a95b81394eca88599d7561735092",
      "8e234d6d865e449eaf5b1ec29be20f16",
      "9dc9767bf77340179cf3c309a52ccb51",
      "5db4315ad27d4322b3cf874bacec6fe1",
      "2d08e7c842f84a51b789998b3c54af3e",
      "35f52cd1dbd04255a2efb59e050cf37a",
      "bb9980de07c641b89990d95ca8f3fa64",
      "24f42cf704b447a5b494bb7fe8ba3448",
      "f39a38df5fe24b8bb0def94a4b92ba2d",
      "4f88df15b9bc422bb5afe6474ecb7d8a",
      "d8ac41e451ba4d3e851f23c88f500e1f",
      "011ce1ae3ac64cb48a22aee6cbdfc602",
      "c4f2ff7a36424a839f8d641c5b3c7188",
      "806ffa28449540049c9492be20ac0a4d",
      "6f5ae7ea8c754eb2896d04d5ad767cd6",
      "464d4850eb4d4a3fbac23f628d5ee014",
      "e78f9b6871cf4c5a865f921809974d60",
      "4cdcab53fbd04b49af7b96a879074f3e",
      "8877ad1273dd418c8035dbf3aa237a8c",
      "63ed4a86469545288117ec20e3e4aa5b",
      "a702e7cbd0a042c38aa013bae91967f0",
      "d3e4d25fa4fe4089b621894f3c776825",
      "e0fa150f7b614a24949d91042a5eeec3",
      "e0dc2659f8c74b58bad9437ed2176432",
      "c9ad2e9ee5104726933fa43b4e3da852",
      "3803f3c4034a48c3afe0a96dafc18acd",
      "9f6072eb43c64ab7bc2a4b8f8852c0e1",
      "f93ffc11e1b34aacabc973d59b1fc0ab",
      "ae36e572f7a3437c84d67cba911a1776",
      "1c6e63397e154e20aaac41c0268e3973",
      "0a911408fd2d400d8fcc0f04dbc8e18a",
      "8bb52fc9d48e4f188f8efa78a6aa7cf9",
      "827276a1d76544b1b00905887574f65c",
      "d2e8c82ad27f4a92b7241be8d9cfaae9",
      "80f6c351c6264a4c8f92e2c75c440600",
      "82eb7d5ee12640b29ba8e03dd41e4e78",
      "630d364704b142ba9810553b2ce890e5",
      "999d42bf53cb4afaa2283cc41f63375d",
      "0f0c2104c4504376823da6bce4d06ea3",
      "cd0c5999da184b939c2c8a2cf1db6b67",
      "6845635ce9524896a19a42a3b4f67e18",
      "75da37a554a94df3a119241133ca5a7e",
      "80df22e935c74ace88096c1d299ffec5",
      "108163678d9840d38ba7d53cff635281",
      "12371430a82a44f78a01bdb013487151",
      "3799275c8d4946f9937962cef0337b0a",
      "e2e0b88ee3004ee2998b70c4b8354437",
      "358fd08c255240298ace5594e868f139",
      "c1687f5509c746648a86d2bf9d4cc615",
      "8cbfbfc42da14ad0a1fd334bf37eab3c"
     ]
    },
    "id": "1748b846",
    "outputId": "70c400e7-a0cc-4acd-e6dc-0afec80427af"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c47de5f6c5b448087a94bc64d14d23f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb9980de07c641b89990d95ca8f3fa64"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "plain_text/validation-00000-of-00001.par(â€¦):   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4cdcab53fbd04b49af7b96a879074f3e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae36e572f7a3437c84d67cba911a1776"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd0c5999da184b939c2c8a2cf1db6b67"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 87599\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 10570\n",
      "    })\n",
      "})\n",
      "Using train subset of size: 20000\n",
      "Using validation subset of size: 5000\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load a dataset from Hugging Face\n",
    "dataset = load_dataset('squad')\n",
    "\n",
    "# Create smaller train/validation subsets to reduce training time\n",
    "train_subset_size = 20000  # you can adjust if needed\n",
    "val_subset_size = 5000\n",
    "\n",
    "train_dataset_small = dataset[\"train\"].shuffle(seed=42).select(range(train_subset_size))\n",
    "validation_dataset_small = dataset[\"validation\"].shuffle(seed=42).select(range(val_subset_size))\n",
    "\n",
    "# Print the dataset structure and subset sizes\n",
    "print(dataset)\n",
    "print(f\"Using train subset of size: {len(train_dataset_small)}\")\n",
    "print(f\"Using validation subset of size: {len(validation_dataset_small)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a52cedb8"
   },
   "source": [
    "Let's inspect a sample from the training split to see the data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e313b619",
    "outputId": "c0e64fa0-36b5-4ea9-d163-fc68e1fc5f8c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'id': '5733be284776f41900661182', 'title': 'University_of_Notre_Dame', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}\n"
     ]
    }
   ],
   "source": [
    "# Display a sample from the training split\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501,
     "referenced_widgets": [
      "edabe092aff54c0b9aaba1942c58c9ae",
      "5841d18b8a2c4a33bd8e7f4d58dc6aa7",
      "8e7536aba99b4d5ea395e5cf95fa855b",
      "304ef5e4a6b7461ba3828f4a21e7c8fa",
      "da2cee0a3d6348a1ae5424e8d58fe1b4",
      "0651724440934e92bae800794fae06cd",
      "9fa3afd8db0f449085808caea957056f",
      "f0ffa8808d99457284f6eced105a6714",
      "066d7c3c54584aab8c22fe411c4325ae",
      "cd5e4f3cd20849d1ad6de2acda70afa0",
      "f5a9c6a147904881be7ca3595d07c799",
      "838b956033fe479da712afe7e0dd7069",
      "84e1e5aaca794e77a5a49435db2fc0ed",
      "96ca63956ea14522837d33c7d5a8d158",
      "65bef967f6484ca5b62aa9098a111d02",
      "7252a50b0e3f487fbb9a52cb7146f845",
      "1f1693ba1af24a9dbe982790697d8a2a",
      "91c7f823a695437fb808476ddee1a489",
      "33dbe82a81004b24b6d8cac343e9dfb6",
      "491ca1ff56d647c4b869daff0d7d1c81",
      "7ec0bf036595453b8d00792a20f84fa4",
      "3398e33f4ee340828c9dfd923c4291f4",
      "ffdb78e9470245b49bccc4bdfa0feb6a",
      "8ca84b79a6e444e7bc5867b8a4ca9254",
      "a81671dc7daf4281a9f24d3eb8e29cab",
      "28731d90ae3d4272a7f3827195ce0a70",
      "62214a283ddc4ddaa8b2f799f2c9aec0",
      "4152381ac9514a60821cc9c7cc9f9b36",
      "9dd49954ef8847629b2c3baa145ee10d",
      "30cdbe5496344feb9a03382265ed0f6e",
      "1b0ed61ffe7c4f74bf9229b4a23101be",
      "b7000479501542e491a6706961aa13f7",
      "9098776c9d6d4953bc18982df2c9836b",
      "7baa4c28ee3f4215a8f29431ff4ec9e5",
      "57eba74a03cb432182bcd647649271fd",
      "09b92aa56a0947399620ed47d6ee6211",
      "4abf8b0d054f40d6930e05445b919b2f",
      "87429199713c4c249c3dc1ef8898946f",
      "ad79eca1f5414c61aa8f09fab0b649fc",
      "f56338eabad7443c8ec023562ab75147",
      "4a4aa5ee2f514f2baa426a72eb2257c4",
      "20ba705a28724556be2da1936632ea6f",
      "2d32af438ca34acaa357e542b4290b65",
      "195d6a8ae0ab405b9a2db2ed4b273130",
      "f6e952bfabeb48729e8c2bc2dbc8daed",
      "efe1b415788543ab8156a207efd7b62f",
      "00a6889603e943008749fe1098f3f1ab",
      "b9cc889a28f4461f81fd7102b96a0120",
      "5ba0f56a88254237bf3ab8131e3abdd3",
      "32e5d68d780c47a3bd4fb4425793a068",
      "c55e56ea05ac4a8eae19cd775134f383",
      "9229c3ebf362457fa741238903dbc3ec",
      "1aa4b65d441c4079a0643a100df44d80",
      "957f1208d1fb4f30841432a927e45bfc",
      "cd13e12e393a47d2b7c232b1f65d6c09",
      "9bce5e9504104fe392fd22c37fa52a19",
      "a6d1a0b1af1e4294aeb6f40ce0c405b8",
      "de4a7c1f8c5645498a31983209a51e8b",
      "d69477980f8d4dd18fe54bd7907ef178",
      "f2423758817e447b81979cfad3a70279",
      "f5c8b4e37d644140afc9ed3afcc4a441",
      "9dc20a1a8786492c885eed867ea07832",
      "09b360d3932f473e9fe95b5f21dfe67c",
      "62ec8389ad194a8f9519cd94d1f6fe43",
      "2ae6f91e5c1c468bbe6a5e644ee4c1f8",
      "4a2cf87189c34b68906d6bf3f0887fba"
     ]
    },
    "id": "MYKcTEQJvhW2",
    "outputId": "40c25c54-1c54-4e61-d36d-d8caacdf76bf"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "edabe092aff54c0b9aaba1942c58c9ae"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "838b956033fe479da712afe7e0dd7069"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ffdb78e9470245b49bccc4bdfa0feb6a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7baa4c28ee3f4215a8f29431ff4ec9e5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6e952bfabeb48729e8c2bc2dbc8daed"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9bce5e9504104fe392fd22c37fa52a19"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DistilBertForQuestionAnswering LOAD REPORT from: distilbert-base-uncased\n",
      "Key                     | Status     | \n",
      "------------------------+------------+-\n",
      "vocab_transform.weight  | UNEXPECTED | \n",
      "vocab_layer_norm.weight | UNEXPECTED | \n",
      "vocab_projector.bias    | UNEXPECTED | \n",
      "vocab_layer_norm.bias   | UNEXPECTED | \n",
      "vocab_transform.bias    | UNEXPECTED | \n",
      "qa_outputs.weight       | MISSING    | \n",
      "qa_outputs.bias         | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded model: distilbert-base-uncased\n",
      "Model parameters: 66.36 Million\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "# Model selection: DistilBERT has ~66M parameters (much less than 3B)\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "print(f\"Loaded model: {model_name}\")\n",
    "print(f\"Model parameters: {model.num_parameters() / 1e6:.2f} Million\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7896e25d"
   },
   "source": [
    "## Step 3: Preprocess Data for Fine-tuning\n",
    "\n",
    "### Important Note:\n",
    "Tokenizer and model must be loaded BEFORE preprocessing. We now have both ready to use in the data preparation step.\n",
    "\n",
    "For the SQuAD dataset, we tokenize questions and contexts. Since answers are spans within the context, we handle answer mapping during tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142,
     "referenced_widgets": [
      "73a314d87a554c2993718e0a6176b913",
      "af1a0c3fa89e46d7999fc50d8adf28ed",
      "efe13cbd5c674a1d835032698662213e",
      "604492ee988e4680acf22c200abe58f8",
      "b84d7bd9742a4c79986bd00b5f13ae5d",
      "bf578299d5604afb9e1db13bbdff9e12",
      "8ea048cd63a144ffb5afff9e53e81f0f",
      "bb083520f8d3401680b2abbeb2bf93c8",
      "95afe976066341c0b6288442b33d09a0",
      "dbbe425d14964a06aadf0b7718ec36c9",
      "36fe722f22d244bab57b57c06532cb54"
     ]
    },
    "id": "7197bdd2",
    "outputId": "b045d107-0ecf-4c47-856b-237b721f3789"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73a314d87a554c2993718e0a6176b913"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original full training dataset size: 87599\n",
      "Training subset size: 20000\n",
      "Tokenized training dataset size (subset): 20196\n",
      "Sample tokenized training example: {'input_ids': [101, 2054, 7017, 1997, 23437, 26847, 2490, 2331, 6531, 2005, 2216, 2975, 7025, 1029, 102, 1996, 29071, 7057, 2006, 4676, 1004, 2270, 2166, 6938, 5279, 2004, 1996, 3587, 5409, 2406, 1999, 1996, 2088, 2005, 3412, 4071, 1012, 1996, 2142, 2163, 3222, 2006, 2248, 3412, 4071, 1010, 1037, 12170, 26053, 2981, 4034, 1997, 1996, 2149, 2231, 1010, 2038, 2872, 5279, 2006, 2049, 3422, 2862, 1997, 3032, 2008, 5478, 2485, 8822, 2349, 2000, 1996, 3267, 1998, 6698, 1997, 13302, 1997, 3412, 4071, 5117, 1999, 2030, 25775, 2011, 1996, 2231, 1012, 2429, 2000, 1037, 2230, 29071, 3795, 13818, 5002, 1010, 6391, 1003, 1997, 23437, 26847, 3569, 1996, 2331, 6531, 2005, 2216, 2040, 2681, 7025, 1025, 6255, 1003, 3569, 23016, 2015, 1998, 6276, 2125, 1997, 2398, 2005, 11933, 1998, 13742, 1025, 1998, 6445, 1003, 2490, 2358, 13369, 1037, 2711, 2040, 27791, 29169, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'start_positions': 97, 'end_positions': 98}\n"
     ]
    }
   ],
   "source": [
    "max_length = 384  # The maximum length of a feature (question and context)\n",
    "stride = 128  # The overlap between consecutive chunks of a context\n",
    "\n",
    "def preprocess_training_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\", # Truncate only the context if it's too long\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = start_char + len(answer[\"text\"][0])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1: # Find where the context starts\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1: # Find where the context ends\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully contained in the current context chunk, set it to (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs\n",
    "\n",
    "# Apply the preprocessing to the (smaller) training subset\n",
    "tokenized_train_dataset = train_dataset_small.map(\n",
    "    preprocess_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset_small.column_names,\n",
    ")\n",
    "\n",
    "print(\"Original full training dataset size:\", len(dataset[\"train\"]))\n",
    "print(\"Training subset size:\", len(train_dataset_small))\n",
    "print(\"Tokenized training dataset size (subset):\", len(tokenized_train_dataset))\n",
    "print(\"Sample tokenized training example:\", tokenized_train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "8dfade4853e24217b1acf352c49b661c",
      "2f7577962bb9443d9c55404b1f4753c9",
      "45117248309e41949349d54bec025aaa",
      "9fe56722d62a41b7b476da8b74fec5eb",
      "db18c1f48f0f41828fa116fd0c9c2bff",
      "f6a34eed580d420d9a77418e4ee3b3ca",
      "913f9905d4e94fbeace9236cc4db69a6",
      "7b5f3ffa0f9a4ad8bbefa23fcdfc8c69",
      "afd040bb8420461db687387df64d9536",
      "3feccc5dc90948a688cdafc9a8151ccc",
      "42bc68e42d824ab89d8dd77f63c7a6d9"
     ]
    },
    "id": "f62701d0",
    "outputId": "c1fb8829-7740-4f2d-a0c3-c5426ccbdd47"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8dfade4853e24217b1acf352c49b661c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original full validation dataset size: 10570\n",
      "Validation subset size: 5000\n",
      "Tokenized validation dataset size (subset): 5099\n"
     ]
    }
   ],
   "source": [
    "def preprocess_validation_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    inputs[\"example_id\"] = [examples[\"id\"][idx] for idx in sample_map]\n",
    "    # Keep offset_mapping for post-processing (no redundant assignment)\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    inputs[\"offset_mapping\"] = offset_mapping\n",
    "\n",
    "    # Add sequence_ids to the features for post-processing\n",
    "    inputs[\"sequence_ids\"] = [inputs.sequence_ids(i) for i in range(len(inputs[\"input_ids\"]))]\n",
    "\n",
    "    return inputs\n",
    "\n",
    "# Apply the preprocessing to the (smaller) validation subset\n",
    "tokenized_validation_dataset = validation_dataset_small.map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=validation_dataset_small.column_names,\n",
    ")\n",
    "\n",
    "print(\"Original full validation dataset size:\", len(dataset[\"validation\"]))\n",
    "print(\"Validation subset size:\", len(validation_dataset_small))\n",
    "print(\"Tokenized validation dataset size (subset):\", len(tokenized_validation_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51d70d20"
   },
   "source": [
    "## Fine-tune Model\n",
    "\n",
    "### Subtask:\n",
    "Fine-tune the selected SLM on the preprocessed text dataset. This will involve setting up training arguments and using the `Trainer` API from the `transformers` library.\n",
    "\n",
    "We'll define a `DataCollatorForQuestionAnswering` to prepare batches and use `TrainingArguments` to configure our training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717,
     "referenced_widgets": [
      "410719dd988d418894430926dd6d416e",
      "9ca9eb690e83483682cb896ab01fc280",
      "13e5484d04514018b36dbcea6abb33d7",
      "5528c4feba2d48dc97688906652de235",
      "919495b1a36b48ce948bc8839a72439c",
      "4a11317b76a24d1f9908911178c1472e",
      "7f7898f6042c43789edb07843b1b08a7",
      "60779198a0fd43768ff45d8f5bca887d",
      "e18922c11ba04f5db12c7b53181c3cfc",
      "40095d9d7f9b4c8c89e93f644c3eec64",
      "e8054f7bc6a74f5991b4628ba494e52b",
      "b77aee43435d4a67bdfc64c0ec288e2a",
      "b6a41e85e9434665adf9a1de82e93bd8",
      "87632fb3a2384c1ca224b83e64d3a446",
      "2d85aba31a71402bb6d453f18b615566",
      "9dafcf049cd94a15ab4639796ac53af9",
      "b7b28dde74744ba99b4f707a04741100",
      "9b66f2d7e76944bbbe94a26add15324e",
      "b050130bbf5e43e9a8f38567cd42ae1e",
      "ee7ffd36868746a6bbb7418cfa41b95e",
      "58ccc60d31614e59a194e83651a8b118",
      "0d493424ae6a41d2afca28e8467c8f93",
      "c1f01779a1ac4489ad0bd3ac29a070df",
      "b61434d5fcb04d1d873e0caf0c64b9c7",
      "e2a5cd3227d9403fa13ea6c66fe5faf9",
      "e2ed9f2b3124496f90c90bb5e88227eb",
      "270fc97ad296468283d62b699d29b206",
      "e7a8327b055743a79aba36f6444b63ff",
      "b0af2f2a6542415fab16b95d64420b95",
      "6008858d03b1448799a2acfa8fa7a871",
      "05153465479b4c5e920a86b9faff15ae",
      "01f35d6c7b264155b5c7893b65fb10b0",
      "3dd3c17fd1e647e9bb56b851b2dd2282",
      "f8143eb14f8e442e80f482a2c2870338",
      "7ea441fb225a49ea8dde5e989aca472f",
      "f10764cec8094cd9b7b4bf44f6451933",
      "0856b991ad994bb88045cea6b38ad35b",
      "430ff502287c42f3a6d1ee2738012b82",
      "dc2e5a59812742b887cd92de65e06954",
      "875aebb55d934595acca8adf88dd626f",
      "92e97f488a8b40b8b2ba190ca2fd6634",
      "709706f633f34b12807d1ce73cf11c61",
      "41068a11365e4022968288a186b7e3fa",
      "415b3ebc89d843a39a0c6ca2bb064d80",
      "da1e7acb78874257b4e3005ee30d9df4",
      "e005e233bfb4454aad39db920a86b077",
      "d3375aa77e8945c6b14c64da74f882d4",
      "f32edebeed1f4663bd9b4d3709e450ac",
      "4f6f024f826b4692af53b83dc20e16d0",
      "bb42d847c3474de895722bba24c52510",
      "dd8700fad73a4d81bb5ab6574d6c0bbd",
      "0c1e7ff445e945c5ab702dfda74195d5",
      "b4f92c33f8a5426aaa3bd698861ac0fa",
      "84d7ad8c7052425180be470c430a1024",
      "1a5fa6dc8066493ea9439ee581e9496e",
      "911cd9cb7dc3486b9fdde3b7d616608c",
      "1e4c341ab2eb456ebe46435492a153ca",
      "4416aeab6f32477cbfb91aca0e1af713",
      "30fffd4c0ae943d6a99557a776fb4898",
      "b9159c2cac8144efb9163eff135f125d",
      "80050d97c73f4472acf8c9cb13218526",
      "7836bb7af8224b019c6df472744caf39",
      "9161b120d0974cea932aa37a621e5066",
      "17d0b962f1f846d7ab372d08c5c72de4",
      "33f150aabdc743028fa0a988d72956d1",
      "50cc1cd4fd264d4383f5a385bb9aa893",
      "ed97817efe4e4749a6ba3594209f8a0a",
      "3768cc01c1b34e84bf9becc8826df449",
      "f0bda2d71735432d9153da9ef39514e9",
      "69f5167f7140475fadc6b3f97911d65b",
      "e48811d6678e40218941878923860eec",
      "3b6cfdd5ed7a43408434b351452330e5",
      "c12a20e7033841cab4047d9cbc3357a6",
      "fa41290910cf4865942b6ce052d68f3f",
      "840e1f851fcf4effb6e6d3409db44ac6",
      "607aad56ed5e478ca868b166ad4ff526",
      "eb51d8d830f44bdca8e25fd08790f61f",
      "d069038829b04f588c0e7a6008eaa313",
      "f1edf9494015441ebe278e85d977f861",
      "f0f62131e94a4e2b9ee5faa82ba49031",
      "8aaa7ccd01ab4bd28bd662b9cca5161a",
      "fee890ad047447dc8507cffbdb71a14e",
      "2ce8c2ac5bba47e19a6293c3585cf931",
      "469c311aa5c54756a4aad8b1f54e55b6",
      "8bd7962140294d90bcc3e0b8fe3fa05d",
      "4aea972bda4145ff8adad55653a526b4",
      "1bb877a312634c658ceced78e52884ed",
      "cd38845c7c8a4a03bae045cf828c15bf",
      "1b3c7eb7aa194f48b8323750b8a36005",
      "e54dcdf9df8542798f48dde72253fb35",
      "02eaac714e7a443982c2887ac8838a66",
      "56c89ecbf2d64b78a616ea9cdc507050",
      "de1807d2c0504a27925d10680630167e",
      "f646c97db97a41019e8cf738249efa6d",
      "3cba385a88524635960605db01d9184c",
      "aac0391a48d44f65aafb3f8860a5925e",
      "68778229c6a74897899e628b4e5c4ad8",
      "f16be7fc622846aeab88710a62edb3a5",
      "491ee0c903b74a3f9fea0cf502ad0591",
      "07d176d6c56d4005af86ad3fc4d0da85",
      "6cecfff5a65543098bd12ef1cfff1f33",
      "5a500c21ee48448985f00ad4c9e58b15",
      "79904c94c3644a6ab19c5570525550d4",
      "36ad595225104486a479de035ed51b4f",
      "e57dc65b3e134fe88909947b38bea80b",
      "44aa9fef1315485c879bffaf3f68b1f5",
      "2cd0a342c94047cc88e4d26248c6f27b",
      "55ec19dd99e04878b46a1f1cfb7aa8f1",
      "cd9305ef5a17404a9d98f3132c0dee39",
      "b8ce4f1986294b7682fc28caded4ceae",
      "b533331167df4c628216a908ae37ffac",
      "fa04afe1402947568221df9aed5085e8",
      "bddcfcc9af3b4793a531069c0b944e4c",
      "90ad3f0029e54b4ebc02e96551f15933",
      "93f8300fb8974c30914555e7bf5f51b4",
      "d097d83f54194ddd97add5165514345f",
      "e2c8da1611044542be97f07b05ca98ed",
      "cc9d42f8425f4ed2ae0a05a30cdeef23",
      "a1685564c5dc4c099dfe9431ec00b26c",
      "cd541ee67c704c2c9c2b046f344c1dd0",
      "65b29715113b48f3914c90947d6a6cd5",
      "4551c54e19aa4b56bce97bd41cd5e572",
      "dd22ab2dd2cb4a588942863bd40cef19",
      "17bf6fd6d7d04afc9555e675a48c3001",
      "79d4fd62d6ed433a906c261858a561af",
      "38df93c3c6ce4e259216270cb40d8efd",
      "749b8d3d987942b5baca4209e86dbca8",
      "2b3f47ca832f471e874966f8da560c6f",
      "03b994d98bb743359fa872a9384c0b55",
      "966bf945d39440108f9b7e0f8ada2ddb",
      "6bb7fdfc963d4cb08346d4873ebff780",
      "8110f3e15c434787be4d9b6b47c3351e",
      "eeaa380871294b779b7bf224066dad03",
      "aff69980f99746e190f2c860df8a04cd",
      "51a57acff29846bb92605c1091e35312",
      "0534877e3863463795642c60a56cfedf",
      "c86761ed2eae424e95f0278ad5b8822e",
      "872cbf0ae1e44249a4f155be8313abce",
      "2c85717750634f899a3ca896a858a6b3",
      "7623c4e42a054b0db4592ab2b9361849",
      "62242d388edd451095403fbd97f30085",
      "e84e9858c44849109ff940bcc68ab8e2",
      "0c5935a7d4914c80a63f16ebca56ac72",
      "f8276aa0bcac40288bcdade315e88df8",
      "14a332d7d5df42799ce7e79d6163adad",
      "df1653cdcefb4c8b8422b7bc129ca7aa",
      "de90fda206a34d3b98bf1749607a20ca",
      "98a97f3eec4b446885ed316793000b64",
      "0fb71390d05e4884a56d2d539b70b03a",
      "25b1db69baa84fe78c4d69abd05ba5ba",
      "f9eaf789274f4ce783bdd4a922563889",
      "ff89e0e23b7b4a2bb730e91962baa6af",
      "d8eb4a74e97642b78e0872ce34797b42",
      "505313ade5dc4871a8cd68ab642c2f63",
      "6674675e3c1040dd980dd92376113d05",
      "88a8ce29e68649e389e14cb374625bd2",
      "b5a126f021ac4cfcbb68bcd84badc7a0",
      "ef29837ec6834acdb94d18d81c7be84d",
      "7187349a2ce04f7f90802215e51fa5c5",
      "88550a3247334e22bedc1e85c1213f6b",
      "650279687f234d23aa64029c7ffa9f81",
      "2909cee2556540a78f8f5c7985ec8b36",
      "55de1993bc2e448f9495784b75157a08",
      "08d23a26564445aea5e61a293a3fd513",
      "f30d9210ec294d9ea028a8e066abe858",
      "29197372c2a040d3bca1fb4c24f01b41",
      "9603259c97874c84a9a8793f4bfef60f",
      "b7f6bd3f40e2416f90979553ed148551",
      "53bd84f524344955891a665ecf3e695e",
      "fc88741e79bd4effb1750a2a1bc08a78",
      "7122cda5131f44e696347aeadd37d78d",
      "5ac4004b8d6049b38e1f0948299e2c18",
      "08d59318dc0f42b688e8dcb8a79f0ca2",
      "620d570475b64a8da0f2e15ca30dda35",
      "8a50c79311fc4c3e97c273044c6b8824",
      "df7064b59de34888b71b537a5a1a70dd"
     ]
    },
    "id": "99e46925",
    "outputId": "da705f33-4e73-4cb4-e7fb-a7ad429ad2ce"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7575' max='7575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7575/7575 20:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.506732</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.101250</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.795915</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "410719dd988d418894430926dd6d416e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b77aee43435d4a67bdfc64c0ec288e2a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1f01779a1ac4489ad0bd3ac29a070df"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f8143eb14f8e442e80f482a2c2870338"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da1e7acb78874257b4e3005ee30d9df4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "911cd9cb7dc3486b9fdde3b7d616608c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed97817efe4e4749a6ba3594209f8a0a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d069038829b04f588c0e7a6008eaa313"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b3c7eb7aa194f48b8323750b8a36005"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "07d176d6c56d4005af86ad3fc4d0da85"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b533331167df4c628216a908ae37ffac"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4551c54e19aa4b56bce97bd41cd5e572"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eeaa380871294b779b7bf224066dad03"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f8276aa0bcac40288bcdade315e88df8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6674675e3c1040dd980dd92376113d05"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "29197372c2a040d3bca1fb4c24f01b41"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7575, training_loss=1.3331631107141475, metrics={'train_runtime': 1217.2309, 'train_samples_per_second': 49.775, 'train_steps_per_second': 6.223, 'total_flos': 5937007518554112.0, 'train_loss': 1.3331631107141475, 'epoch': 3.0})"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "\n",
    "# Define a data collator. This will pad your batches to the longest example in each batch.\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\", # Corrected argument name\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True, # Enable mixed precision training for faster training if GPU is available\n",
    "    push_to_hub=False, # Set to True if you want to push your model to Hugging Face Hub\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_validation_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fe587402"
   },
   "source": [
    "## Evaluate Model Performance\n",
    "\n",
    "### Subtask:\n",
    "Evaluate the fine-tuned model using suitable metrics.\n",
    "\n",
    "For Question Answering on SQuAD, we will calculate Exact Match (EM) and F1 Score. This requires generating predictions, post-processing them to extract answers, and then comparing with the ground truth using the SQuAD evaluation script from the `evaluate` library."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"Generating predictions on the (smaller) validation subset...\")\n",
    "raw_predictions = trainer.predict(tokenized_validation_dataset)\n",
    "\n",
    "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size=20, max_answer_length=30):\n",
    "    all_start_logits, all_end_logits = raw_predictions\n",
    "\n",
    "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "    for i, feature in enumerate(features):\n",
    "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "    # The dictionary to fill with the processed predictions\n",
    "    predictions = collections.OrderedDict()\n",
    "\n",
    "    # tqdm displays progress bar.\n",
    "    print(\"Post-processing predictions...\")\n",
    "    for example_index, example in enumerate(tqdm(examples)):\n",
    "        feature_indices = features_per_example[example_index]\n",
    "        min_null_score = None\n",
    "        valid_answers = []\n",
    "\n",
    "        context = example[\"context\"]\n",
    "        for feature_index in feature_indices:\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    if (start_index >= len(offset_mapping) or\n",
    "                        end_index >= len(offset_mapping) or\n",
    "                        offset_mapping[start_index] is None or\n",
    "                        offset_mapping[end_index] is None or\n",
    "                        offset_mapping[start_index][0] < 0 or\n",
    "                        offset_mapping[end_index][0] < 0 or\n",
    "                        start_index > end_index or\n",
    "                        (features[feature_index][\"sequence_ids\"][start_index] != 1 or\n",
    "                         features[feature_index][\"sequence_ids\"][end_index] != 1)):\n",
    "                        continue\n",
    "\n",
    "                    length = offset_mapping[end_index][1] - offset_mapping[start_index][0]\n",
    "                    if length > max_answer_length:\n",
    "                        continue\n",
    "\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"offsets\": (offset_mapping[start_index][0], offset_mapping[end_index][1]),\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"start_logit\": start_logits[start_index],\n",
    "                            \"end_logit\": end_logits[end_index],\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        if len(valid_answers) > 0:\n",
    "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        else:\n",
    "            # In the event that all valid answers have been filtered out, return an empty string\n",
    "            best_answer = {\"offsets\": (0, 0), \"score\": 0.0, \"start_logit\": 0.0, \"end_logit\": 0.0}\n",
    "\n",
    "        # If the null answer has a better score than the best non-null answer, then return null answer.\n",
    "        if min_null_score is not None and min_null_score > best_answer[\"score\"]:\n",
    "            predictions[example[\"id\"]] = \"\"\n",
    "        else:\n",
    "            predictions[example[\"id\"]] = context[best_answer[\"offsets\"][0] : best_answer[\"offsets\"][1]]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Call the post-processing function on the validation subset\n",
    "final_predictions = postprocess_qa_predictions(\n",
    "    validation_dataset_small, tokenized_validation_dataset, raw_predictions.predictions\n",
    ")\n",
    "\n",
    "print(\"Finished generating and post-processing predictions on the validation subset.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "61e848ee277d4026a9526e45235caf1d",
      "515caf16ace247c2b00ebb733b6c664c",
      "8d49109886ee40329ec8e4ceaf63caad",
      "ce12e7d456ba45a499262bf86cd8b964",
      "f8f80d1a82284daa97de23e1d91acf42",
      "691f1fa37e3046b1abc61ceacc509243",
      "88e1ea37cc5242fe92666ab90275f21b",
      "ef40aa9a286e42d3b78b9eebbd91db11",
      "755967da89a446da8c05d86545f1f938",
      "401d54d9db4f45e595a56920001729ae",
      "631531931b514cd386c9adb84b7ec049"
     ]
    },
    "id": "-2EJpwX_HWbs",
    "outputId": "a53aebf4-d613-4963-823c-2a34f04bee6b"
   },
   "execution_count": null,
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions on the (smaller) validation subset...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing predictions...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e848ee277d4026a9526e45235caf1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished generating and post-processing predictions on the validation subset.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Compute SQuAD metrics (Exact Match and F1) on the validation subset\n",
    "# This cell only depends on `final_predictions` and `validation_dataset_small`.\n",
    "\n",
    "!pip install evaluate  # safe to re-run; does nothing if already installed\n",
    "import evaluate\n",
    "\n",
    "print(\"Computing SQuAD metrics (Exact Match and F1) on validation subset...\")\n",
    "\n",
    "# Load the SQuAD evaluation script\n",
    "squad_metric = evaluate.load(\"squad\")\n",
    "\n",
    "# Prepare the references in the format expected by the SQuAD metric\n",
    "references = [\n",
    "    {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]}\n",
    "    for ex in validation_dataset_small\n",
    "]\n",
    "\n",
    "# Convert final_predictions (dict id -> text) to the list-of-dicts format expected by the metric\n",
    "predictions_for_metric = [\n",
    "    {\"id\": qid, \"prediction_text\": pred_text}\n",
    "    for qid, pred_text in final_predictions.items()\n",
    "]\n",
    "\n",
    "# Compute the metrics\n",
    "eval_results = squad_metric.compute(predictions=predictions_for_metric, references=references)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SQuAD Evaluation Results (on validation subset):\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Exact Match (EM): {eval_results['exact_match']:.4f}\")\n",
    "print(f\"F1 Score: {eval_results['f1']:.4f}\")\n",
    "print(\"=\"*60)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "osrpxI70Hc09",
    "outputId": "fbcacf5e-6348-4eb2-eb1d-6e3292be370d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (1.3.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (0.21.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2026.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.7.0->evaluate) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.7.0->evaluate) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.7.0->evaluate) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.7.0->evaluate) (8.3.1)\n",
      "Computing SQuAD metrics (Exact Match and F1) on validation subset...\n",
      "\n",
      "============================================================\n",
      "SQuAD Evaluation Results (on validation subset):\n",
      "============================================================\n",
      "Exact Match (EM): 67.5800\n",
      "F1 Score: 77.6290\n",
      "============================================================\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vC_vt_b8vhW4"
   },
   "source": [
    "## Summary and Observations\n",
    "\n",
    "### Task Completion:\n",
    "âœ“ **Dataset Selected**: SQuAD - Different from standard classification tasks  \n",
    "âœ“ **Model Selected**: DistilBERT (~66M parameters) - Much less than 3B limit  \n",
    "âœ“ **Task Completed**: Question Answering fine-tuning  \n",
    "âœ“ **Evaluation Metrics**: Exact Match (EM) and F1 Score (standard for QA)  \n",
    "âœ“ **Results Displayed**: Clear performance metrics shown  \n",
    "\n",
    "### Key Implementation Details:\n",
    "1. **DistilBERT Model**: Compact version of BERT (66M vs 110M parameters)\n",
    "2. **Data Preprocessing**: Tokenization with sliding window approach for long contexts\n",
    "3. **Training Configuration**: 3 epochs with learning rate 2e-5\n",
    "4. **Evaluation**: SQuAD metrics using HuggingFace evaluate library\n",
    "5. **GPU Acceleration**: Mixed precision training (fp16) enabled for faster training\n",
    "\n",
    "### Results Interpretation:\n",
    "- **Exact Match**: Percentage of predictions matching ground truth exactly\n",
    "- **F1 Score**: Harmonic mean of precision and recall at token level\n",
    "- Higher values indicate better model performance on QA task"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}